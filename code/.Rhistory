PUMA20,
PUMA20_name = NA_character_,
CZ90,
CZ90_name,
pop_overlap = pop_overlap,
share_of_PUMA20 = ifelse(pop_from > 0, pop_overlap / pop_from, 0),
PUMA20_total_pop = pop_from,
cells = cells,
grid_res_m = !!cell_m,
crs_epsg   = !!epsg,
method     = !!method_tag
) |>
as.data.frame()
}
# tiny FIPS -> USPS mapper (for convenience in output)
fips_to_usps <- c(
"01"="AL","02"="AK","04"="AZ","05"="AR","06"="CA","08"="CO","09"="CT","10"="DE","11"="DC",
"12"="FL","13"="GA","15"="HI","16"="ID","17"="IL","18"="IN","19"="IA","20"="KS","21"="KY",
"22"="LA","23"="ME","24"="MD","25"="MA","26"="MI","27"="MN","28"="MS","29"="MO","30"="MT",
"31"="NE","32"="NV","33"="NH","34"="NJ","35"="NM","36"="NY","37"="NC","38"="ND","39"="OH",
"40"="OK","41"="OR","42"="PA","44"="RI","45"="SC","46"="SD","47"="TN","48"="TX","49"="UT",
"50"="VT","51"="VA","53"="WA","54"="WV","55"="WI","56"="WY","60"="AS","66"="GU","69"="MP",
"72"="PR","78"="VI"
)
# ---- read polygons, add integer codes ----
# TO: CZ1990
cz90 <- read_std(file.path(dir_1990, "cz.shp"), "cz", "cz_name")
cz90_map <- make_code_map(cz90); cz90 <- left_join(cz90, cz90_map, by="id")
nm_cz90 <- st_drop_geometry(cz90) |> select(id, name)
# FROM: PUMA2020
puma20 <- read_std(file.path(dir_2020, "ipums_puma_2020.shp"), "GISJOIN", "Name")
puma20_map <- make_code_map(puma20); puma20 <- left_join(puma20, puma20_map, by="id")
nm_p20 <- st_drop_geometry(puma20) |> select(id, name)
# narrow to 'code' for rasterization
cz90_for_rast   <- cz90   |> select(code, geometry)
puma20_for_rast <- puma20 |> select(code, geometry)
# ---- read ALL state population rasters (national run) ----
tifs <- list.files(grid_dir, pattern = "^[A-Z]{2}_grid100m_pop_2020_.*\\.tif$", full.names = TRUE)
stopifnot(length(tifs) > 0)
# national totals for PUMA20 on the grid
acc_totals <- data.table(code_from=integer(), pop_from=numeric())
# accumulator for pairs (no state tagging here)
acc_pairs <- data.table(code_from=integer(), code_to=integer(), cells=integer(), pop_overlap=numeric())
for (ti in tifs) {
message("\n----- ", basename(ti), " -----")
r <- terra::rast(ti) |> ensure_crs(epsg)
# Crop FROM to raster bbox; includes any PUMA intersecting this raster
from_s <- suppressWarnings(st_intersection(puma20_for_rast, bbox_sf(r)))
if (nrow(from_s) == 0L) { gc(); next }
# totals for this raster (PUMA20)
t_res <- pairs_for_target(r, from_s, from_s)$totals
if (nrow(t_res)) {
if (nrow(acc_totals)) {
acc_totals <- merge(acc_totals, t_res, by="code_from", all=TRUE, suffixes=c(".x",".y"))
acc_totals[, pop_from := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_from.x","pop_from.y")]
acc_totals[, c("pop_from.x","pop_from.y") := NULL]
} else acc_totals <- t_res
}
# pairs to CZ90 (national CZs)
to_s <- suppressWarnings(st_intersection(cz90_for_rast, bbox_sf(r)))
if (nrow(to_s) == 0L) { gc(); next }
res <- pairs_for_target(r, from_s, to_s)$pairs
if (nrow(res)) {
acc_pairs <- rbindlist(list(acc_pairs, res), use.names=TRUE, fill=TRUE)
}
gc()
}
# collapse duplicates across rasters
if (nrow(acc_pairs)) {
acc_pairs <- acc_pairs[, .(cells = sum(cells), pop_overlap = sum(pop_overlap)), by = .(code_from, code_to)]
}
out <- finalize_p20_to_cz90(
pairs_dt  = acc_pairs,
totals_dt = acc_totals,
from_map  = puma20_map,
to_map    = cz90_map,
to_names  = nm_cz90
)
# drop placeholder name then attach PUMA names (optional)
out$PUMA20_name <- NULL
out <- out |>
left_join(nm_p20 |> rename(PUMA20 = id, PUMA20_name = name), by = "PUMA20")
View(out)
# --- add state_fips (positions 2–3 of PUMA20) and USPS state ---
out <- out |>
mutate(
state_fips = stringr::str_sub(PUMA20, 2, 3),
state      = fips_to_usps[ state_fips ] |> as.character()
)
# convenience: afactor alias
out$afactor <- out$share_of_PUMA20
# sanity: verify each PUMA sums to ~1 nationally
sums <- out |>
group_by(PUMA20) |>
summarise(afactor_sum = sum(afactor, na.rm=TRUE), .groups = "drop")
bad <- sums |> filter(abs(afactor_sum - 1) > 1e-6)
View(bad)
if (nrow(bad)) {
message("WARNING: ", nrow(bad), " PUMA(s) not summing to 1. If any remain, inspect those PUMA IDs or widen inputs.")
}
fname <- "puma20_to_cz90_popgrid100m_area.csv"
readr::write_csv(out, file.path(out_dir, fname))
message("Wrote: ", fname, " (", nrow(out), " rows)")
# Also write national PUMA20 totals on the grid for QA
readr::write_csv(as.data.frame(acc_totals), file.path(out_dir, "puma20_grid_totals_NATIONAL.csv"))
message("\nDone. Crosswalk in: ", out_dir)
gc()
# ==========================================================
# National crosswalks: CZ20 -> {CZ90, PUMA20, PUMA2010, CZ2010, CZ2000}
# Uses 100 m population GeoTIFFs (EPSG:5070) across ALL states.
# Output: one national CSV per target geography.
# ==========================================================
suppressPackageStartupMessages({
library(sf); library(dplyr); library(data.table); library(readr); library(stringr); library(terra); library(tibble)
})
sf::sf_use_s2(FALSE)
# ---- paths ----
base_root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
input_dir <- file.path(base_root, "input")
dir_1990  <- file.path(input_dir, "processed", "boundaries_1990")
dir_2020  <- file.path(input_dir, "processed", "boundaries_2020")
dir_2010  <- file.path(input_dir, "processed", "boundaries_2010")
dir_cz10  <- file.path(input_dir, "2010 boundaries")
dir_cz00  <- file.path(input_dir, "2000 boundaries")
grid_dir  <- file.path(base_root, "output", "population_grid")
out_dir   <- file.path(base_root, "output", "crosswalks"); dir.create(out_dir, TRUE, TRUE)
# ---- settings ----
epsg <- 5070
cell_m <- 100
method_tag <- "building_footprint_area"
# ---- helpers ----
read_std <- function(fp, id_col, name_col = NULL) {
g <- st_read(fp, quiet = TRUE) |> st_make_valid() |> st_transform(epsg)
g |> mutate(id = as.character(.data[[id_col]]),
name = if (!is.null(name_col) && name_col %in% names(g)) as.character(.data[[name_col]]) else NA_character_) |>
select(id, name, geometry)
}
make_code_map <- function(sfobj) data.frame(id = unique(sfobj$id), code = seq_along(unique(sfobj$id)))
bbox_sf <- function(r) sf::st_as_sf(terra::as.polygons(terra::ext(r), crs = terra::crs(r)))
safe_blocks <- function(x){ bs <- try(terra::blocks(x), TRUE); if(inherits(bs,"try-error")||is.null(dim(bs))||nrow(bs)==0L) data.frame(row=1L,nrows=terra::nrow(x)) else bs }
ensure_crs <- function(r, epsg){ if (terra::crs(r, proj=TRUE)=="") terra::crs(r) <- st_crs(epsg)$wkt; r }
safe_read_values <- function(s,row,nrows){ v <- terra::readValues(s,row=row,nrows=nrows); if(is.null(v)) return(NULL); if(is.matrix(v)) return(v); nl <- terra::nlyr(s); if(nl==0L) return(NULL); matrix(v, ncol=nl) }
pairs_for_target <- function(r_pop, from_for_rast, to_for_rast) {
r_pop <- ensure_crs(r_pop, epsg)
bb <- bbox_sf(r_pop)
from_s <- suppressWarnings(st_intersection(from_for_rast, bb)) |> select(code, geometry)
to_s   <- suppressWarnings(st_intersection(to_for_rast,   bb)) |> select(code, geometry)
if (nrow(from_s)==0L || nrow(to_s)==0L) return(list(pairs=data.table(), totals=data.table()))
r_from <- terra::rasterize(terra::vect(from_s), r_pop, field="code", background=NA)
r_to   <- terra::rasterize(terra::vect(to_s),   r_pop, field="code", background=NA)
s123 <- c(r_pop, r_from, r_to); on.exit(try(terra::readStop(s123), silent=TRUE), add=TRUE); terra::readStart(s123)
bs <- safe_blocks(s123)
pairs <- data.table(code_from=integer(), code_to=integer(), cells=integer(), pop_overlap=numeric())
totals<- data.table(code_from=integer(), pop_from=numeric())
for (i in seq_len(nrow(bs))) {
m <- safe_read_values(s123, bs$row[i], bs$nrows[i]); if (is.null(m)) next
pop <- m[,1]; cf <- m[,2]; ct <- m[,3]
okf <- !is.na(pop) & !is.na(cf) & pop>0
if (any(okf)) {
t1 <- data.table(code_from=cf[okf], pop_from=pop[okf])[, .(pop_from=sum(pop_from)), by=code_from]
if (nrow(totals)) {
totals <- merge(totals, t1, by="code_from", all=TRUE, suffixes=c(".x",".y"))
totals[, pop_from := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_from.x","pop_from.y")]
totals[, c("pop_from.x","pop_from.y") := NULL]
} else totals <- t1
}
ok <- !is.na(pop) & !is.na(cf) & !is.na(ct) & pop>0
if (any(ok)) {
p1 <- data.table(code_from=cf[ok], code_to=ct[ok], cells=1L, pop_overlap=pop[ok])[
, .(cells=sum(cells), pop_overlap=sum(pop_overlap)), by=.(code_from, code_to)]
if (nrow(pairs)) {
pairs <- merge(pairs, p1, by=c("code_from","code_to"), all=TRUE, suffixes=c(".x",".y"))
pairs[, cells := rowSums(.SD, na.rm=TRUE), .SDcols=c("cells.x","cells.y")]
pairs[, pop_overlap := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_overlap.x","pop_overlap.y")]
pairs[, c("cells.x","cells.y","pop_overlap.x","pop_overlap.y") := NULL]
} else pairs <- p1
}
if (i %% 5 == 0) gc()
}
list(pairs=pairs, totals=totals)
}
# ---- final table builder (no 'state' column from raster) ----
finalize_table <- function(pairs_dt, totals_dt, from_map, to_map, to_names, target_label) {
if (!nrow(pairs_dt)) return(data.frame())
from_lu <- from_map |> rename(CZ20 = id, code_from = code)
to_lu   <- to_map   |> left_join(to_names, by = "id") |>
rename(!!target_label := id, !!paste0(target_label,"_name") := name, code_to = code)
res <- pairs_dt |>
left_join(totals_dt, by="code_from") |>
left_join(from_lu,   by="code_from") |>
left_join(to_lu,     by="code_to") |>
transmute(
CZ20,
!!target_label := .data[[target_label]],
!!paste0(target_label,"_name") := .data[[paste0(target_label,"_name")]],
pop_overlap = pop_overlap,
share_of_CZ20 = ifelse(pop_from > 0, pop_overlap / pop_from, 0),
afactor       = share_of_CZ20,
CZ20_total_pop = pop_from,
cells = cells,
grid_res_m = !!cell_m,
crs_epsg   = !!epsg,
method     = !!method_tag
) |>
as.data.frame()
# Add PUMA state_fips/state when the target is PUMA*
if (target_label %in% c("PUMA20","PUMA2010")) {
fips_to_usps <- c(
"01"="AL","02"="AK","04"="AZ","05"="AR","06"="CA","08"="CO","09"="CT","10"="DE","11"="DC",
"12"="FL","13"="GA","15"="HI","16"="ID","17"="IL","18"="IN","19"="IA","20"="KS","21"="KY",
"22"="LA","23"="ME","24"="MD","25"="MA","26"="MI","27"="MN","28"="MS","29"="MO","30"="MT",
"31"="NE","32"="NV","33"="NH","34"="NJ","35"="NM","36"="NY","37"="NC","38"="ND","39"="OH",
"40"="OK","41"="OR","42"="PA","44"="RI","45"="SC","46"="SD","47"="TN","48"="TX","49"="UT",
"50"="VT","51"="VA","53"="WA","54"="WV","55"="WI","56"="WY","60"="AS","66"="GU","69"="MP",
"72"="PR","78"="VI"
)
tid <- res[[target_label]]
state_fips <- stringr::str_sub(tid, 2, 3)
res$state_fips <- state_fips
res$state      <- unname(fips_to_usps[state_fips])
}
res
}
# ---- read polygons, add codes ----
cz20   <- read_std(file.path(dir_2020, "cz20.shp"),                 "CZ20")
cz90   <- read_std(file.path(dir_1990, "cz.shp"),                   "cz",      "cz_name")
puma20 <- read_std(file.path(dir_2020, "ipums_puma_2020.shp"),      "GISJOIN", "Name")
puma10 <- read_std(file.path(dir_2010, "ipums_puma_2010_tl20.shp"), "GISJOIN", "Name")
ers10  <- read_std(file.path(dir_cz10, "ERS10.rep.shp"),            "LM_Code")
ers00  <- read_std(file.path(dir_cz00, "ERS00.shp"),                "LM_Code")
cz20_map   <- make_code_map(cz20);   cz20   <- left_join(cz20,   cz20_map,   by="id")
cz90_map   <- make_code_map(cz90);   cz90   <- left_join(cz90,   cz90_map,   by="id")
puma20_map <- make_code_map(puma20); puma20 <- left_join(puma20, puma20_map, by="id")
puma10_map <- make_code_map(puma10); puma10 <- left_join(puma10, puma10_map, by="id")
ers10_map  <- make_code_map(ers10);  ers10  <- left_join(ers10,  ers10_map,  by="id")
ers00_map  <- make_code_map(ers00);  ers00  <- left_join(ers00,  ers00_map,  by="id")
nm_cz90 <- st_drop_geometry(cz90)   |> select(id, name)
nm_p20  <- st_drop_geometry(puma20) |> select(id, name)
nm_p10  <- st_drop_geometry(puma10) |> select(id, name)
nm_e10  <- st_drop_geometry(ers10)  |> select(id, name)
nm_e00  <- st_drop_geometry(ers00)  |> select(id, name)
cz20_for_rast   <- cz20   |> select(code, geometry)
cz90_for_rast   <- cz90   |> select(code, geometry)
puma20_for_rast <- puma20 |> select(code, geometry)
puma10_for_rast <- puma10 |> select(code, geometry)
ers10_for_rast  <- ers10  |> select(code, geometry)
ers00_for_rast  <- ers00  |> select(code, geometry)
# ---- NATIONAL run over ALL state TIFs ----
tifs <- list.files(grid_dir, pattern = "^[A-Z]{2}_grid100m_pop_2020_.*\\.tif$", full.names = TRUE)
stopifnot(length(tifs) > 0)
acc_totals <- data.table(code_from=integer(), pop_from=numeric())  # national CZ20 totals on grid
acc <- list(
CZ90     = data.table(),
PUMA20   = data.table(),
PUMA2010 = data.table(),
CZ2010   = data.table(),
CZ2000   = data.table()
)
for (ti in tifs) {
message("\n----- ", basename(ti), " -----")
r <- terra::rast(ti) |> ensure_crs(epsg)
bb <- bbox_sf(r)
# source = CZ20 inside raster bbox
from_s <- suppressWarnings(st_intersection(cz20_for_rast, bb))
if (nrow(from_s) == 0L) { gc(); next }
# totals for this raster
t_res <- pairs_for_target(r, from_s, from_s)$totals
if (nrow(t_res)) {
if (nrow(acc_totals)) {
acc_totals <- merge(acc_totals, t_res, by="code_from", all=TRUE, suffixes=c(".x",".y"))
acc_totals[, pop_from := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_from.x","pop_from.y")]
acc_totals[, c("pop_from.x","pop_from.y") := NULL]
} else acc_totals <- t_res
}
# accumulate pairs for each target
do_one <- function(target_for_rast, key) {
t_s <- suppressWarnings(st_intersection(target_for_rast, bb))
if (nrow(t_s)==0L) return(invisible(NULL))
res <- pairs_for_target(r, from_s, t_s)$pairs
if (nrow(res)) acc[[key]] <<- rbindlist(list(acc[[key]], res), use.names=TRUE, fill=TRUE)
invisible(NULL)
}
do_one(cz90_for_rast,   "CZ90")
do_one(puma20_for_rast, "PUMA20")
do_one(puma10_for_rast, "PUMA2010")
do_one(ers10_for_rast,  "CZ2010")
do_one(ers00_for_rast,  "CZ2000")
gc()
}
# collapse duplicates across rasters (national)
collapse_nat <- function(dt) {
if (!nrow(dt)) return(dt)
dt[, .(cells = sum(cells), pop_overlap = sum(pop_overlap)), by = .(code_from, code_to)]
}
acc <- lapply(acc, collapse_nat)
# ---- finalize & write (one CSV per geography) ----
final_write <- function(key, target_label, to_map, to_names, filename) {
if (!nrow(acc[[key]])) { message("No rows for ", key); return(invisible(NULL)) }
out <- finalize_table(
pairs_dt  = acc[[key]],
totals_dt = acc_totals,
from_map  = cz20_map,
to_map    = to_map,
to_names  = to_names,
target_label = target_label
)
# Optional QA: afactor sums for each CZ20
qa <- out |>
group_by(CZ20) |>
summarise(afactor_sum = sum(afactor, na.rm=TRUE), .groups="drop") |>
filter(abs(afactor_sum - 1) > 1e-6)
if (nrow(qa)) message("WARNING (", target_label, "): ", nrow(qa), " CZ20(s) not summing to 1.")
readr::write_csv(out, file.path(out_dir, filename))
message("Wrote: ", filename, " (", nrow(out), " rows)")
}
final_write("CZ90",     "CZ90",     cz90_map,   nm_cz90, "cz20_to_cz90_popgrid100m_area.csv")
final_write("PUMA20",   "PUMA20",   puma20_map, nm_p20,  "cz20_to_puma20_popgrid100m_area.csv")
final_write("PUMA2010", "PUMA2010", puma10_map, nm_p10,  "cz20_to_puma2010_popgrid100m_area.csv")
final_write("CZ2010",   "CZ2010",   ers10_map,  nm_e10,  "cz20_to_cz2010_popgrid100m_area.csv")
final_write("CZ2000",   "CZ2000",   ers00_map,  nm_e00,  "cz20_to_cz2000_popgrid100m_area.csv")
# (Optional) national CZ20 totals on the grid for QA
readr::write_csv(as.data.frame(acc_totals), file.path(out_dir, "cz20_grid_totals_NATIONAL.csv"))
message("\nDone. Crosswalks in: ", out_dir)
sums <- out |>
group_by(PUMA20) |>
summarise(afactor_sum = sum(afactor, na.rm=TRUE), .groups = "drop")
View(cz20)
gc()
suppressPackageStartupMessages({
library(dplyr); library(readr); library(stringr); library(tibble)
})
suppressPackageStartupMessages({
library(dplyr); library(readr); library(stringr); library(tibble)
})
# ---- paths ----
base_root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
out_dir   <- file.path(base_root, "output", "crosswalks")
qa_dir    <- file.path(out_dir, "qa"); dir.create(qa_dir, showWarnings = FALSE, recursive = TRUE)
# ---- settings ----
tol <- 1e-6  # tolerance for |sum(afactor)-1|
digits_report <- 12  # round in report for readability
# ---- helpers ----
safe_read <- function(fp) {
tryCatch(readr::read_csv(fp, show_col_types = FALSE), error = function(e) NULL)
}
check_sums <- function(df, source_col, weight_col = "afactor", file_label = NA_character_) {
if (is.null(df)) return(tibble())
need <- c(source_col, weight_col)
if (!all(need %in% names(df))) {
warning("Missing required columns in ", file_label, ": ", paste(setdiff(need, names(df)), collapse=", "))
return(tibble())
}
df |>
transmute(src = .data[[source_col]], w = .data[[weight_col]]) |>
group_by(src) |>
summarise(
afactor_sum = sum(w, na.rm = TRUE),
n_parts     = n(),
n_na        = sum(is.na(w)),
min_part    = suppressWarnings(min(w, na.rm = TRUE)),
max_part    = suppressWarnings(max(w, na.rm = TRUE)),
.groups = "drop"
) |>
mutate(
abs_err   = abs(afactor_sum - 1),
ok        = abs_err <= tol
) |>
filter(!ok) |>
mutate(
afactor_sum = round(afactor_sum, digits_report),
abs_err     = round(abs_err, digits_report),
file        = file_label,
source_col  = source_col
) |>
select(file, source_col, src, afactor_sum, abs_err, n_parts, n_na, min_part, max_part)
}
write_report <- function(tbl, out_path) {
if (nrow(tbl)) {
readr::write_csv(tbl, out_path)
message("Wrote QA report: ", out_path, " (", nrow(tbl), " bad sources)")
} else {
message("All good: ", out_path, " (no bad sources)")
# still drop an empty file so the run is traceable
readr::write_csv(tibble(note="no issues found", generated=as.character(Sys.time())), out_path)
}
}
# ---- discover files ----
all_csvs <- list.files(out_dir, pattern = "\\.csv$", full.names = TRUE)
# PUMA20 -> CZ90 national
puma_file <- all_csvs[str_detect(basename(all_csvs), "^puma20_to_cz90_.*_NATIONAL\\.csv$")]
# CZ20 -> {CZ90,PUMA20,PUMA2010,CZ2010,CZ2000} nationals
cz20_files <- all_csvs[str_detect(basename(all_csvs), "^cz20_to_.*_NATIONAL\\.csv$")]
# ---- run checks ----
summary_rows <- list()
# 1) PUMA20->CZ90: group by PUMA20
if (length(puma_file)) {
for (fp in puma_file) {
df <- safe_read(fp)
bad <- check_sums(df, source_col = "PUMA20", weight_col = "afactor", file_label = basename(fp))
outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
} else {
message("No PUMA20->CZ90 national file found.")
}
# 2) CZ20->* : group by CZ20
for (fp in cz20_files) {
df <- safe_read(fp)
bad <- check_sums(df, source_col = "CZ20", weight_col = "afactor", file_label = basename(fp))
outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
# ---- combined summary ----
combined <- if (length(summary_rows)) dplyr::bind_rows(summary_rows) else tibble(
file = character(), source_col = character(), src = character(),
afactor_sum = numeric(), abs_err = numeric(), n_parts = integer(),
n_na = integer(), min_part = numeric(), max_part = numeric()
)
# 2) CZ20->* : group by CZ20
for (fp in cz20_files) {
df <- safe_read(fp)
bad <- check_sums(df, source_col = "CZ20", weight_col = "afactor", file_label = basename(fp))
outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
# ---- combined summary ----
combined <- if (length(summary_rows)) dplyr::bind_rows(summary_rows) else tibble(
file = character(), source_col = character(), src = character(),
afactor_sum = numeric(), abs_err = numeric(), n_parts = integer(),
n_na = integer(), min_part = numeric(), max_part = numeric()
)
View(combined)
suppressPackageStartupMessages({
library(dplyr); library(readr); library(stringr)
})
# ---- paths ----
base_root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
cross_dir <- file.path(base_root, "output", "crosswalks")
# ---- list of files you want to check ----
files <- c(
"cz20_to_cz90_popgrid100m_area_NATIONAL.csv",
"cz20_to_puma20_popgrid100m_area_NATIONAL.csv",
"cz20_to_puma2010_popgrid100m_area_NATIONAL.csv",
"cz20_to_cz2010_popgrid100m_area_NATIONAL.csv",
"cz20_to_cz2000_popgrid100m_area_NATIONAL.csv"
)
# ---- function to check one file ----
check_file <- function(fname, tol = 1e-6) {
fpath <- file.path(cross_dir, fname)
if (!file.exists(fpath)) {
message("File not found: ", fname)
return(NULL)
}
message("\nChecking: ", fname)
df <- readr::read_csv(fpath, show_col_types = FALSE)
bad <- df %>%
group_by(CZ20) %>%
summarise(sum_afactor = sum(afactor, na.rm = TRUE), .groups="drop") %>%
filter(abs(sum_afactor - 1) > tol)
if (nrow(bad) == 0) {
message("✅ All CZ20 afactor sums ≈ 1")
} else {
message("⚠️  Found ", nrow(bad), " CZ20(s) with bad afactor sums")
print(bad, n = 20)  # show up to 20
}
invisible(bad)
}
# ---- run check on all files ----
bad_list <- lapply(files, check_file)
# ---- list of files you want to check ----
files <- c(
"cz20_to_cz90_popgrid100m_area.csv",
"cz20_to_puma20_popgrid100m_area.csv",
"cz20_to_puma2010_popgrid100m_area.csv",
"cz20_to_cz2010_popgrid100m_area.csv",
"cz20_to_cz2000_popgrid100m_area.csv"
)
# ---- function to check one file ----
check_file <- function(fname, tol = 1e-6) {
fpath <- file.path(cross_dir, fname)
if (!file.exists(fpath)) {
message("File not found: ", fname)
return(NULL)
}
message("\nChecking: ", fname)
df <- readr::read_csv(fpath, show_col_types = FALSE)
bad <- df %>%
group_by(CZ20) %>%
summarise(sum_afactor = sum(afactor, na.rm = TRUE), .groups="drop") %>%
filter(abs(sum_afactor - 1) > tol)
if (nrow(bad) == 0) {
message("✅ All CZ20 afactor sums ≈ 1")
} else {
message("⚠️  Found ", nrow(bad), " CZ20(s) with bad afactor sums")
print(bad, n = 20)  # show up to 20
}
invisible(bad)
}
# ---- run check on all files ----
bad_list <- lapply(files, check_file)
# combine into one data.frame if you want to export
bad_all <- dplyr::bind_rows(
lapply(seq_along(bad_list), function(i) {
if (is.null(bad_list[[i]])) return(NULL)
bad_list[[i]] %>%
mutate(file = files[i])
})
)
View(bad_all)

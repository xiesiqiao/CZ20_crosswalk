outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
} else {
message("No PUMA20->CZ90 national file found.")
}
# 2) CZ20->* : group by CZ20
for (fp in cz20_files) {
df <- safe_read(fp)
bad <- check_sums(df, source_col = "CZ20", weight_col = "afactor", file_label = basename(fp))
outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
# ---- combined summary ----
combined <- if (length(summary_rows)) dplyr::bind_rows(summary_rows) else tibble(
file = character(), source_col = character(), src = character(),
afactor_sum = numeric(), abs_err = numeric(), n_parts = integer(),
n_na = integer(), min_part = numeric(), max_part = numeric()
)
# 2) CZ20->* : group by CZ20
for (fp in cz20_files) {
df <- safe_read(fp)
bad <- check_sums(df, source_col = "CZ20", weight_col = "afactor", file_label = basename(fp))
outp <- file.path(qa_dir, paste0(tools::file_path_sans_ext(basename(fp)), "_QA_bad.csv"))
write_report(bad, outp)
if (nrow(bad)) summary_rows[[length(summary_rows)+1]] <- bad
}
# ---- combined summary ----
combined <- if (length(summary_rows)) dplyr::bind_rows(summary_rows) else tibble(
file = character(), source_col = character(), src = character(),
afactor_sum = numeric(), abs_err = numeric(), n_parts = integer(),
n_na = integer(), min_part = numeric(), max_part = numeric()
)
View(combined)
suppressPackageStartupMessages({
library(dplyr); library(readr); library(stringr)
})
# ---- paths ----
base_root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
cross_dir <- file.path(base_root, "output", "crosswalks")
# ---- list of files you want to check ----
files <- c(
"cz20_to_cz90_popgrid100m_area_NATIONAL.csv",
"cz20_to_puma20_popgrid100m_area_NATIONAL.csv",
"cz20_to_puma2010_popgrid100m_area_NATIONAL.csv",
"cz20_to_cz2010_popgrid100m_area_NATIONAL.csv",
"cz20_to_cz2000_popgrid100m_area_NATIONAL.csv"
)
# ---- function to check one file ----
check_file <- function(fname, tol = 1e-6) {
fpath <- file.path(cross_dir, fname)
if (!file.exists(fpath)) {
message("File not found: ", fname)
return(NULL)
}
message("\nChecking: ", fname)
df <- readr::read_csv(fpath, show_col_types = FALSE)
bad <- df %>%
group_by(CZ20) %>%
summarise(sum_afactor = sum(afactor, na.rm = TRUE), .groups="drop") %>%
filter(abs(sum_afactor - 1) > tol)
if (nrow(bad) == 0) {
message("✅ All CZ20 afactor sums ≈ 1")
} else {
message("⚠️  Found ", nrow(bad), " CZ20(s) with bad afactor sums")
print(bad, n = 20)  # show up to 20
}
invisible(bad)
}
# ---- run check on all files ----
bad_list <- lapply(files, check_file)
# ---- list of files you want to check ----
files <- c(
"cz20_to_cz90_popgrid100m_area.csv",
"cz20_to_puma20_popgrid100m_area.csv",
"cz20_to_puma2010_popgrid100m_area.csv",
"cz20_to_cz2010_popgrid100m_area.csv",
"cz20_to_cz2000_popgrid100m_area.csv"
)
# ---- function to check one file ----
check_file <- function(fname, tol = 1e-6) {
fpath <- file.path(cross_dir, fname)
if (!file.exists(fpath)) {
message("File not found: ", fname)
return(NULL)
}
message("\nChecking: ", fname)
df <- readr::read_csv(fpath, show_col_types = FALSE)
bad <- df %>%
group_by(CZ20) %>%
summarise(sum_afactor = sum(afactor, na.rm = TRUE), .groups="drop") %>%
filter(abs(sum_afactor - 1) > tol)
if (nrow(bad) == 0) {
message("✅ All CZ20 afactor sums ≈ 1")
} else {
message("⚠️  Found ", nrow(bad), " CZ20(s) with bad afactor sums")
print(bad, n = 20)  # show up to 20
}
invisible(bad)
}
# ---- run check on all files ----
bad_list <- lapply(files, check_file)
# combine into one data.frame if you want to export
bad_all <- dplyr::bind_rows(
lapply(seq_along(bad_list), function(i) {
if (is.null(bad_list[[i]])) return(NULL)
bad_list[[i]] %>%
mutate(file = files[i])
})
)
View(bad_all)
# Adds PUMA code & GEOID (2010/2020) to the three crosswalk CSVs.
# Joins on: statefp (already in your CSVs) + the CSV's PUMA column.
# Output: same folder, with suffix "_enriched.csv".
library(sf)
library(dplyr)
library(readr)
library(stringr)
# ---- EDIT THESE PATHS ----
root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
in_dir <- file.path(root, "input")
dir_2020  <- file.path(input_dir, "processed", "boundaries_2020")
dir_2020  <- file.path(in_dir, "processed", "boundaries_2020")
dir_2010  <- file.path(in_dir, "processed", "boundaries_2010")
puma20 <- read_std(file.path(dir_2020, "ipums_puma_2020.shp"))
# ---- add_puma_ids.R ---------------------------------------------------------
# Adds PUMA code & GEOID (2010/2020) to the three crosswalk CSVs.
library(sf)
library(dplyr)
library(readr)
library(stringr)
# ---- PATHS ----
# shapefiles
shp2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2010/ipums_puma_2010_tl20.shp"
shp2020 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2020/ipums_puma_2020.shp"
# csvs
csv_2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma2010_popgrid100m_area.csv"
csv_2020a <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma20_popgrid100m_area.csv"
csv_2020b <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/puma20_to_cz90_popgrid100m_area.csv"
# If your CSVs use different PUMA column names, list them (first found is used):
puma_cols_2010 <- c("puma2010","puma10","puma","puma_code")
puma_cols_2020 <- c("puma20","puma","puma_code")
# ---- helpers ----
pick_col <- function(df, candidates) {
hit <- candidates[candidates %in% names(df)]
if (length(hit) == 0) stop("None of these columns were found: ", paste(candidates, collapse=", "))
hit[1]
}
std_puma_lut <- function(gdf, year = c("2010","2020")) {
year <- match.arg(year)
gdf <- st_drop_geometry(gdf)
state_col <- intersect(c("STATEFP","STATEFP20","STATEFP10","STATEFP00"), names(gdf))[1]
if (is.na(state_col)) stop("STATEFP column not found in shapefile.")
statefp <- str_pad(as.character(gdf[[state_col]]), 2, "left", "0")
code_candidates <- c("PUMACE20","PUMACE10","PUMACE","PUMA5CE","PUMA","PUMACE_20","PUMACE_10")
code_col <- intersect(code_candidates, names(gdf))
code_col <- if (length(code_col)) code_col[1] else NA_character_
puma_code <- if (!is.na(code_col)) {
str_pad(str_extract(as.character(gdf[[code_col]]), "\\d+"), 5, "left", "0")
} else NA_character_
geoid_candidates <- c("GEOID20","GEOID10","GEOID")
geoid_col <- intersect(geoid_candidates, names(gdf))
geoid_col <- if (length(geoid_col)) geoid_col[1] else NA_character_
puma_geoid <- if (!is.na(geoid_col)) as.character(gdf[[geoid_col]]) else NA_character_
if (any(is.na(puma_geoid)) && !all(is.na(puma_code))) {
puma_geoid <- ifelse(is.na(puma_geoid),
paste0(statefp, puma_code),
puma_geoid)
}
if (any(is.na(puma_code)) && !all(is.na(puma_geoid))) {
puma_code <- ifelse(is.na(puma_code),
str_sub(puma_geoid, -5),
puma_code)
}
tibble(
statefp = statefp,
puma_code = str_pad(puma_code, 5, "left", "0"),
puma_geoid = str_pad(puma_geoid, 7, "left", "0")
) |>
distinct() |>
rename_with(~paste0(.x, "_", year), c(puma_code, puma_geoid))
}
enrich_file <- function(csv_path, lut, year, puma_candidates) {
message("Enriching: ", csv_path)
df <- read_csv(csv_path, show_col_types = FALSE) |>
mutate(statefp = str_pad(as.character(statefp), 2, "left", "0"))
pcol <- pick_col(df, puma_candidates)
df <- df |>
mutate(.puma_code_join = str_pad(str_extract(as.character(.data[[pcol]]), "\\d+"), 5, "left", "0"))
out <- df |>
left_join(lut, by = c("statefp" = paste0("statefp_", year),
".puma_code_join" = paste0("puma_code_", year))) |>
select(-.puma_code_join)
out_path <- sub("\\.csv$", "_enriched.csv", csv_path)
write_csv(out, out_path)
message("  -> wrote: ", out_path)
}
# ---- build lookups & run ----
lut10_raw <- st_read(shp2010, quiet = TRUE)
lut20_raw <- st_read(shp2020, quiet = TRUE)
# ---- add_puma_ids_by_GISJOIN.R -------------------------------------------
library(sf)
library(dplyr)
library(readr)
# 1) Paths ------------------------------------------------------------------
shp2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2010/ipums_puma_2010_tl20.shp"
shp2020 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2020/ipums_puma_2020.shp"
csv_2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma2010_popgrid100m_area.csv"
csv_2020a <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma20_popgrid100m_area.csv"
csv_2020b <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/puma20_to_cz90_popgrid100m_area.csv"
# 2) Read shapefiles and keep only GISJOIN, PUMA, GEOID ---------------------
p10 <- st_read(shp2010, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, puma_code_2010 = PUMA, puma_geoid_2010 = GEOID)
p20 <- st_read(shp2020, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, puma_code_2020 = PUMA, puma_geoid_2020 = GEOID)
# ---- add_puma_ids_by_GISJOIN.R -------------------------------------------
library(sf)
library(dplyr)
library(readr)
# 1) Paths ------------------------------------------------------------------
shp2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2010/ipums_puma_2010_tl20.shp"
shp2020 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/input/processed/boundaries_2020/ipums_puma_2020.shp"
csv_2010 <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma2010_popgrid100m_area.csv"
csv_2020a <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/cz20_to_puma20_popgrid100m_area.csv"
csv_2020b <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk/output/crosswalks/puma20_to_cz90_popgrid100m_area.csv"
# 2) Read shapefiles and keep only GISJOIN, PUMA, GEOID ---------------------
p10 <- st_read(shp2010, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, puma_code_2010 = PUMA, puma_geoid_2010 = GEOID)
p20 <- st_read(shp2020, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, puma_code_2020 = PUMA, puma_geoid_2020 = GEOID)
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
left_join(p10, by = "GISJOIN")
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE)
x2 <- read_csv(csv_2020a, show_col_types = FALSE) #|>
x3 <- read_csv(csv_2020b, show_col_types = FALSE)# |>
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
left_join(p10, by = c("PUMA2010"="GISJOIN"))
View(x1)
# 2) Read shapefiles and keep only GISJOIN, PUMA, GEOID ---------------------
p10 <- st_read(shp2010, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, PUMA2010 = PUMA, PUMA10_GEOID = GEOID)
p20 <- st_read(shp2020, quiet = TRUE) |>
st_drop_geometry() |>
select(GISJOIN, PUMA2020 = PUMA, PUMA200_GEOID = GEOID)
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
rename(PUMA2010=PUMA2010_GISJOIN) |>
left_join(p10, by = c("PUMA2010"="GISJOIN"))
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
rename(PUMA2010_GISJOIN=PUMA2010) |>
left_join(p10, by = c("PUMA2010"="GISJOIN"))
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
rename(PUMA2010_GISJOIN=PUMA2010) |>
left_join(p10, by = c("PUMA2010_GISJOIN"="GISJOIN"))
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
rename(PUMA2010_GISJOIN=PUMA2010) |>
left_join(p10, by = c("PUMA2010_GISJOIN"="GISJOIN"))|>
select(CZ20, PUMA2010,everything())
View(x2)
View(x1)
# 3) Join to CSVs -----------------------------------------------------------
x1 <- read_csv(csv_2010, show_col_types = FALSE) |>
rename(PUMA2010_GISJOIN=PUMA2010) |>
left_join(p10, by = c("PUMA2010_GISJOIN"="GISJOIN"))|>
select(CZ20, PUMA2010,state_fips,afactor,everything())
View(x1)
write_csv(x1, sub("\\.csv$", "_enriched.csv", csv_2010))
write_csv(x1, sub("\\.csv$", "", csv_2010))
x2 <- read_csv(csv_2020a, show_col_types = FALSE) |>
rename(PUMA20_GISJOIN=PUMA20) |>
left_join(p20, by = c("PUMA20_GISJOIN"="GISJOIN"))|>
select(CZ20, PUMA2020,state_fips,afactor,everything())
View(x2)
write_csv(x2, sub("\\.csv$", "", csv_2020a))
x3 <- read_csv(csv_2020b, show_col_types = FALSE) #|>
x3 <- read_csv(csv_2020b, show_col_types = FALSE) |>
rename(PUMA20_GISJOIN=PUMA20) |>
left_join(p20, by = c("PUMA20_GISJOIN"="GISJOIN"))|>
select(PUMA2020,state_fips,CZ90, afactor,everything())
View(x3)
write_csv(x3, sub("\\.csv$", "", csv_2020b))
# ==========================================================
# National crosswalks (reversed): {PUMA20, PUMA2010} -> CZ20
# Uses 100 m population GeoTIFFs (EPSG:5070) across ALL states.
# Output: one national CSV per PUMA source geography.
# ==========================================================
suppressPackageStartupMessages({
library(sf); library(dplyr); library(data.table); library(readr); library(stringr); library(terra); library(tibble)
})
sf::sf_use_s2(FALSE)
# ---- paths ----
base_root <- "C:/Users/xiesi/ASU Dropbox/Xie Sijiao/Connor-Kemeny-Storper/Microdata_wealth_estimates/Crosswalk/CZ20_CZ90_xwalk"
input_dir <- file.path(base_root, "input")
dir_1990  <- file.path(input_dir, "processed", "boundaries_1990")
dir_2020  <- file.path(input_dir, "processed", "boundaries_2020")
dir_2010  <- file.path(input_dir, "processed", "boundaries_2010")
dir_cz10  <- file.path(input_dir, "2010 boundaries")
dir_cz00  <- file.path(input_dir, "2000 boundaries")
grid_dir  <- file.path(base_root, "output", "population_grid")
out_dir   <- file.path(base_root, "output", "crosswalks"); dir.create(out_dir, TRUE, TRUE)
# ---- settings ----
epsg <- 5070
cell_m <- 100
method_tag <- "building_footprint_area"
# ---- helpers ----
read_std <- function(fp, id_col, name_col = NULL) {
g <- st_read(fp, quiet = TRUE) |> st_make_valid() |> st_transform(epsg)
g |> mutate(id = as.character(.data[[id_col]]),
name = if (!is.null(name_col) && name_col %in% names(g)) as.character(.data[[name_col]]) else NA_character_) |>
select(id, name, geometry)
}
make_code_map <- function(sfobj) data.frame(id = unique(sfobj$id), code = seq_along(unique(sfobj$id)))
bbox_sf <- function(r) sf::st_as_sf(terra::as.polygons(terra::ext(r), crs = terra::crs(r)))
safe_blocks <- function(x){ bs <- try(terra::blocks(x), TRUE); if(inherits(bs,"try-error")||is.null(dim(bs))||nrow(bs)==0L) data.frame(row=1L,nrows=terra::nrow(x)) else bs }
ensure_crs <- function(r, epsg){ if (terra::crs(r, proj=TRUE)=="") terra::crs(r) <- st_crs(epsg)$wkt; r }
safe_read_values <- function(s,row,nrows){ v <- terra::readValues(s,row=row,nrows=nrows); if(is.null(v)) return(NULL); if(is.matrix(v)) return(v); nl <- terra::nlyr(s); if(nl==0L) return(NULL); matrix(v, ncol=nl) }
pairs_for_target <- function(r_pop, from_for_rast, to_for_rast) {
r_pop <- ensure_crs(r_pop, epsg)
bb <- bbox_sf(r_pop)
from_s <- suppressWarnings(st_intersection(from_for_rast, bb)) |> select(code, geometry)
to_s   <- suppressWarnings(st_intersection(to_for_rast,   bb)) |> select(code, geometry)
if (nrow(from_s)==0L || nrow(to_s)==0L) return(list(pairs=data.table(), totals=data.table()))
r_from <- terra::rasterize(terra::vect(from_s), r_pop, field="code", background=NA)
r_to   <- terra::rasterize(terra::vect(to_s),   r_pop, field="code", background=NA)
s123 <- c(r_pop, r_from, r_to); on.exit(try(terra::readStop(s123), silent=TRUE), add=TRUE); terra::readStart(s123)
bs <- safe_blocks(s123)
pairs <- data.table(code_from=integer(), code_to=integer(), cells=integer(), pop_overlap=numeric())
totals<- data.table(code_from=integer(), pop_from=numeric())
for (i in seq_len(nrow(bs))) {
m <- safe_read_values(s123, bs$row[i], bs$nrows[i]); if (is.null(m)) next
pop <- m[,1]; cf <- m[,2]; ct <- m[,3]
okf <- !is.na(pop) & !is.na(cf) & pop>0
if (any(okf)) {
t1 <- data.table(code_from=cf[okf], pop_from=pop[okf])[, .(pop_from=sum(pop_from)), by=code_from]
if (nrow(totals)) {
totals <- merge(totals, t1, by="code_from", all=TRUE, suffixes=c(".x",".y"))
totals[, pop_from := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_from.x","pop_from.y")]
totals[, c("pop_from.x","pop_from.y") := NULL]
} else totals <- t1
}
ok <- !is.na(pop) & !is.na(cf) & !is.na(ct) & pop>0
if (any(ok)) {
p1 <- data.table(code_from=cf[ok], code_to=ct[ok], cells=1L, pop_overlap=pop[ok])[
, .(cells=sum(cells), pop_overlap=sum(pop_overlap)), by=.(code_from, code_to)]
if (nrow(pairs)) {
pairs <- merge(pairs, p1, by=c("code_from","code_to"), all=TRUE, suffixes=c(".x",".y"))
pairs[, cells := rowSums(.SD, na.rm=TRUE), .SDcols=c("cells.x","cells.y")]
pairs[, pop_overlap := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_overlap.x","pop_overlap.y")]
pairs[, c("cells.x","cells.y","pop_overlap.x","pop_overlap.y") := NULL]
} else pairs <- p1
}
if (i %% 5 == 0) gc()
}
list(pairs=pairs, totals=totals)
}
# ---- final table builder (generic FROM -> TO) ----
finalize_table_generic <- function(pairs_dt, totals_dt, from_map, to_map, from_names, to_names, from_label, to_label) {
if (!nrow(pairs_dt)) return(data.frame())
from_lu <- from_map |> left_join(from_names, by = "id") |>
rename(!!from_label := id, !!paste0(from_label,"_name") := name, code_from = code)
to_lu   <- to_map   |> left_join(to_names, by = "id") |>
rename(!!to_label := id, !!paste0(to_label,"_name") := name, code_to = code)
res <- pairs_dt |>
left_join(totals_dt, by="code_from") |>
left_join(from_lu,   by="code_from") |>
left_join(to_lu,     by="code_to") |>
transmute(
!!from_label := .data[[from_label]],
!!paste0(from_label,"_name") := .data[[paste0(from_label,"_name")]],
!!to_label   := .data[[to_label]],
!!paste0(to_label,"_name") := .data[[paste0(to_label,"_name")]],
pop_overlap = pop_overlap,
!!paste0("share_of_", from_label) := ifelse(pop_from > 0, pop_overlap / pop_from, 0),
afactor       = !!as.name(paste0("share_of_", from_label)),
!!paste0(from_label, "_total_pop") := pop_from,
cells = cells,
grid_res_m = !!cell_m,
crs_epsg   = !!epsg,
method     = !!method_tag
) |>
as.data.frame()
# Add state fields for any PUMA columns present (either FROM or TO)
add_puma_state <- function(df, col_label){
fips_to_usps <- c(
"01"="AL","02"="AK","04"="AZ","05"="AR","06"="CA","08"="CO","09"="CT","10"="DE","11"="DC",
"12"="FL","13"="GA","15"="HI","16"="ID","17"="IL","18"="IN","19"="IA","20"="KS","21"="KY",
"22"="LA","23"="ME","24"="MD","25"="MA","26"="MI","27"="MN","28"="MS","29"="MO","30"="MT",
"31"="NE","32"="NV","33"="NH","34"="NJ","35"="NM","36"="NY","37"="NC","38"="ND","39"="OH",
"40"="OK","41"="OR","42"="PA","44"="RI","45"="SC","46"="SD","47"="TN","48"="TX","49"="UT",
"50"="VT","51"="VA","53"="WA","54"="WV","55"="WI","56"="WY","60"="AS","66"="GU","69"="MP",
"72"="PR","78"="VI"
)
tid <- df[[col_label]]
if (!is.null(tid)) {
state_fips <- stringr::str_sub(tid, 2, 3)
df[[paste0(col_label,"_state_fips")]] <- state_fips
df[[paste0(col_label,"_state")]]      <- unname(fips_to_usps[state_fips])
}
df
}
if (from_label %in% c("PUMA20","PUMA2010")) res <- add_puma_state(res, from_label)
if (to_label   %in% c("PUMA20","PUMA2010")) res <- add_puma_state(res, to_label)
res
}
# ---- read polygons, add codes ----
cz20   <- read_std(file.path(dir_2020, "cz20.shp"),                 "CZ20")
cz90   <- read_std(file.path(dir_1990, "cz.shp"),                   "cz",      "cz_name")
puma20 <- read_std(file.path(dir_2020, "ipums_puma_2020.shp"),      "GISJOIN", "Name")
puma10 <- read_std(file.path(dir_2010, "ipums_puma_2010_tl20.shp"), "GISJOIN", "Name")
ers10  <- read_std(file.path(dir_cz10, "ERS10.rep.shp"),            "LM_Code")
ers00  <- read_std(file.path(dir_cz00, "ERS00.shp"),                "LM_Code")
cz20_map   <- make_code_map(cz20);   cz20   <- left_join(cz20,   cz20_map,   by="id")
cz90_map   <- make_code_map(cz90);   cz90   <- left_join(cz90,   cz90_map,   by="id")
puma20_map <- make_code_map(puma20); puma20 <- left_join(puma20, puma20_map, by="id")
puma10_map <- make_code_map(puma10); puma10 <- left_join(puma10, puma10_map, by="id")
ers10_map  <- make_code_map(ers10);  ers10  <- left_join(ers10,  ers10_map,  by="id")
ers00_map  <- make_code_map(ers00);  ers00  <- left_join(ers00,  ers00_map,  by="id")
nm_cz20 <- st_drop_geometry(cz20)   |> select(id, name)
nm_cz90 <- st_drop_geometry(cz90)   |> select(id, name)
nm_p20  <- st_drop_geometry(puma20) |> select(id, name)
nm_p10  <- st_drop_geometry(puma10) |> select(id, name)
nm_e10  <- st_drop_geometry(ers10)  |> select(id, name)
nm_e00  <- st_drop_geometry(ers00)  |> select(id, name)
cz20_for_rast   <- cz20   |> select(code, geometry)
cz90_for_rast   <- cz90   |> select(code, geometry)
puma20_for_rast <- puma20 |> select(code, geometry)
puma10_for_rast <- puma10 |> select(code, geometry)
ers10_for_rast  <- ers10  |> select(code, geometry)
ers00_for_rast  <- ers00  |> select(code, geometry)
# ---- generic national run over ALL state TIFs for (FROM -> TO) ----
tifs <- list.files(grid_dir, pattern = "^[A-Z]{2}_grid100m_pop_2020_.*\\.tif$", full.names = TRUE)
stopifnot(length(tifs) > 0)
collapse_nat <- function(dt) {
if (!nrow(dt)) return(dt)
dt[, .(cells = sum(cells), pop_overlap = sum(pop_overlap)), by = .(code_from, code_to)]
}
run_nat_xwalk <- function(from_for_rast, to_for_rast) {
acc_totals <- data.table(code_from=integer(), pop_from=numeric())
acc_pairs  <- data.table()
for (ti in tifs) {
message("\n----- ", basename(ti), " -----")
r <- terra::rast(ti) |> ensure_crs(epsg)
bb <- bbox_sf(r)
from_s <- suppressWarnings(st_intersection(from_for_rast, bb))
to_s   <- suppressWarnings(st_intersection(to_for_rast,   bb))
if (nrow(from_s) == 0L || nrow(to_s) == 0L) { gc(); next }
# totals for FROM on this raster
t_res <- pairs_for_target(r, from_s, from_s)$totals
if (nrow(t_res)) {
if (nrow(acc_totals)) {
acc_totals <- merge(acc_totals, t_res, by="code_from", all=TRUE, suffixes=c(".x",".y"))
acc_totals[, pop_from := rowSums(.SD, na.rm=TRUE), .SDcols=c("pop_from.x","pop_from.y")]
acc_totals[, c("pop_from.x","pop_from.y") := NULL]
} else acc_totals <- t_res
}
# pairs FROM -> TO on this raster
res <- pairs_for_target(r, from_s, to_s)$pairs
if (nrow(res)) acc_pairs <- rbindlist(list(acc_pairs, res), use.names=TRUE, fill=TRUE)
gc()
}
list(pairs = collapse_nat(acc_pairs), totals = acc_totals)
}
# ---- PUMA20 -> CZ20 ----
res_p20_cz20 <- run_nat_xwalk(puma20_for_rast, cz20_for_rast)
out_p20_cz20 <- finalize_table_generic(
pairs_dt  = res_p20_cz20$pairs,
totals_dt = res_p20_cz20$totals,
from_map  = puma20_map, to_map = cz20_map,
from_names = nm_p20,    to_names = nm_cz20,
from_label = "PUMA20",  to_label = "CZ20"
)
# QA: afactor sums per PUMA20 should be 1
qa_p20 <- out_p20_cz20 |>
group_by(PUMA20) |>
summarise(afactor_sum = sum(afactor, na.rm=TRUE), .groups="drop") |>
filter(abs(afactor_sum - 1) > 1e-6)
if (nrow(qa_p20)) message("WARNING (PUMA20->CZ20): ", nrow(qa_p20), " PUMA20(s) not summing to 1.")
readr::write_csv(out_p20_cz20, file.path(out_dir, "puma20_to_cz20_popgrid100m_area.csv"))
readr::write_csv(as.data.frame(res_p20_cz20$totals), file.path(out_dir, "puma20_grid_totals_NATIONAL.csv"))
message("Wrote: puma20_to_cz20_popgrid100m_area.csv (", nrow(out_p20_cz20), " rows)")
# ---- PUMA2010 -> CZ20 ----
res_p10_cz20 <- run_nat_xwalk(puma10_for_rast, cz20_for_rast)
out_p10_cz20 <- finalize_table_generic(
pairs_dt  = res_p10_cz20$pairs,
totals_dt = res_p10_cz20$totals,
from_map  = puma10_map, to_map = cz20_map,
from_names = nm_p10,    to_names = nm_cz20,
from_label = "PUMA2010", to_label = "CZ20"
)
# QA: afactor sums per PUMA2010 should be 1
qa_p10 <- out_p10_cz20 |>
group_by(PUMA2010) |>
summarise(afactor_sum = sum(afactor, na.rm=TRUE), .groups="drop") |>
filter(abs(afactor_sum - 1) > 1e-6)
if (nrow(qa_p10)) message("WARNING (PUMA2010->CZ20): ", nrow(qa_p10), " PUMA2010(s) not summing to 1.")
readr::write_csv(out_p10_cz20, file.path(out_dir, "puma2010_to_cz20_popgrid100m_area.csv"))
readr::write_csv(as.data.frame(res_p10_cz20$totals), file.path(out_dir, "puma2010_grid_totals_NATIONAL.csv"))
message("Wrote: puma2010_to_cz20_popgrid100m_area.csv (", nrow(out_p10_cz20), " rows)")
message("\nDone. Crosswalks in: ", out_dir)
